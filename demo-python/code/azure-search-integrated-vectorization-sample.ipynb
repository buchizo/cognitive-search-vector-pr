{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Azure Cognitive Search Integrated Vectorization Sample\n",
        "This code demonstrates how to use Azure Cognitive Search as a Vector store by automatically chunking and generating embeddings using the Azure OpenAI Embedding skill as part of the skillset pipeline in Azure Cognitive Search. \n",
        "## Prerequisites\n",
        "To run the code, install the following packages. This sample currently uses version `11.4.0b12`. Please note, that integrated vectorization feature is in preview and has not been published to [azure-search-documents](https://pypi.org/project/azure-search-documents/#description) on pypi. If you'd like to use this feature, please reference the whl file. We hope to publish an updated version soon!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#import sys\n",
        "#sys.path.append('/anaconda/envs/azureml_py38/lib/python3.8/site-packages')\n",
        "#! pip uninstall azure-search-documents -y"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1698512365250
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install ./whl/azure_search_documents-11.4.0b12-py3-none-any.whl --quiet  \n",
        "! pip install openai azure-storage-blob python-dotenv --quiet"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Import required libraries and environment variables"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries  \n",
        "from azure.core.credentials import AzureKeyCredential  \n",
        "from azure.search.documents import SearchClient\n",
        "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient  \n",
        "from azure.search.documents.models import (\n",
        "    QueryAnswerType,\n",
        "    QueryCaptionType,\n",
        "    QueryLanguage,\n",
        "    QueryType,\n",
        "    RawVectorQuery,\n",
        "    VectorizableTextQuery,\n",
        "    VectorFilterMode,    \n",
        ")\n",
        "from azure.search.documents.indexes.models import (  \n",
        "    AzureOpenAIEmbeddingSkill,  \n",
        "    AzureOpenAIParameters,  \n",
        "    AzureOpenAIVectorizer,  \n",
        "    ExhaustiveKnnParameters,  \n",
        "    ExhaustiveKnnVectorSearchAlgorithmConfiguration,\n",
        "    FieldMapping,  \n",
        "    HnswParameters,  \n",
        "    HnswVectorSearchAlgorithmConfiguration,  \n",
        "    IndexProjectionMode,  \n",
        "    InputFieldMappingEntry,  \n",
        "    OutputFieldMappingEntry,  \n",
        "    PrioritizedFields,    \n",
        "    SearchField,  \n",
        "    SearchFieldDataType,  \n",
        "    SearchIndex,  \n",
        "    SearchIndexer,  \n",
        "    SearchIndexerDataContainer,  \n",
        "    SearchIndexerDataSourceConnection,  \n",
        "    SearchIndexerIndexProjectionSelector,  \n",
        "    SearchIndexerIndexProjections,  \n",
        "    SearchIndexerIndexProjectionsParameters,  \n",
        "    SearchIndexerSkillset,  \n",
        "    SemanticConfiguration,  \n",
        "    SemanticField,  \n",
        "    SemanticSettings,  \n",
        "    SplitSkill,  \n",
        "    VectorSearch,  \n",
        "    VectorSearchAlgorithmKind,  \n",
        "    VectorSearchAlgorithmMetric,  \n",
        "    VectorSearchProfile,  \n",
        ")  \n",
        "from azure.storage.blob import BlobServiceClient  \n",
        "import openai  \n",
        "from dotenv import load_dotenv  \n",
        "import os  \n",
        "  \n",
        "# Configure environment variables  \n",
        "load_dotenv()  \n",
        "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")  \n",
        "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")  \n",
        "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")  \n",
        "openai.api_type = \"azure\"  \n",
        "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")  \n",
        "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  \n",
        "openai.api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")  \n",
        "model: str = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL\")  \n",
        "blob_connection_string = os.getenv(\"BLOB_CONNECTION_STRING\")  \n",
        "container_name = os.getenv(\"BLOB_CONTAINER_NAME\")  \n",
        "credential = AzureKeyCredential(key)  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1698512367362
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Blob Storage  \n",
        "Retrieve documents from Blob Storage. You can use the sample documents in the [documents](../data/documents) folder.  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Blob Storage\n",
        "blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
        "container_client = blob_service_client.get_container_client(container_name)\n",
        "blobs = container_client.list_blobs()\n",
        "\n",
        "first_blob = next(blobs)\n",
        "blob_url = container_client.get_blob_client(first_blob).url\n",
        "print(f\"URL of the first blob: {blob_url}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1698512378475
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect your Blob Storage to a data source in Cognitive Search"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data source \n",
        "ds_client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))\n",
        "container = SearchIndexerDataContainer(name=container_name)\n",
        "data_source_connection = SearchIndexerDataSourceConnection(\n",
        "    name=f\"{index_name}-blob\",\n",
        "    type=\"azureblob\",\n",
        "    connection_string=blob_connection_string,\n",
        "    container=container\n",
        ")\n",
        "data_source = ds_client.create_or_update_data_source_connection(data_source_connection)\n",
        "\n",
        "print(f\"Data source '{data_source.name}' created or updated\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1698512429372
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a search index"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a search index  \n",
        "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)  \n",
        "fields = [  \n",
        "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),  \n",
        "    SearchField(name=\"title\", type=SearchFieldDataType.String),  \n",
        "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),  \n",
        "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False, analyzer_name=\"ja.lucene\"),  # 分割されたテキストが入る。テキスト検索用にアナライザーは日本語Luceneを指定\n",
        "    SearchField(name=\"blob\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),  # titleにBlob名が入るがソースのBlobパスがあったほうが都合が良いので追加\n",
        "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=1536, vector_search_profile=\"myHnswProfile\"),  # 次元数1536はOpenAIのEmbeddingモデルの応答から\n",
        "]  \n",
        "  \n",
        "# Configure the vector search configuration  \n",
        "vector_search = VectorSearch(  \n",
        "    algorithms=[  \n",
        "        HnswVectorSearchAlgorithmConfiguration(  \n",
        "            name=\"myHnsw\",  \n",
        "            kind=VectorSearchAlgorithmKind.HNSW,  \n",
        "            parameters=HnswParameters(  \n",
        "                m=4,  \n",
        "                ef_construction=400,  \n",
        "                ef_search=500,  \n",
        "                metric=VectorSearchAlgorithmMetric.COSINE,  \n",
        "            ),  \n",
        "        ),  \n",
        "        ExhaustiveKnnVectorSearchAlgorithmConfiguration(  \n",
        "            name=\"myExhaustiveKnn\",  \n",
        "            kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,  \n",
        "            parameters=ExhaustiveKnnParameters(  \n",
        "                metric=VectorSearchAlgorithmMetric.COSINE,  \n",
        "            ),  \n",
        "        ),  \n",
        "    ],  \n",
        "    profiles=[  \n",
        "        VectorSearchProfile(  \n",
        "            name=\"myHnswProfile\",  \n",
        "            algorithm=\"myHnsw\",  \n",
        "            vectorizer=\"myOpenAI\",  \n",
        "        ),  \n",
        "        VectorSearchProfile(  \n",
        "            name=\"myExhaustiveKnnProfile\",  \n",
        "            algorithm=\"myExhaustiveKnn\",  \n",
        "            vectorizer=\"myOpenAI\",  \n",
        "        ),  \n",
        "    ],  \n",
        "    vectorizers=[  \n",
        "        AzureOpenAIVectorizer(  \n",
        "            name=\"myOpenAI\",  \n",
        "            kind=\"azureOpenAI\",  \n",
        "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
        "                resource_uri=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),  \n",
        "                deployment_id=model,  \n",
        "                api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
        "            ),  \n",
        "        ),  \n",
        "    ],  \n",
        ")  \n",
        "  \n",
        "semantic_config = SemanticConfiguration(  \n",
        "    name=\"my-semantic-config\",  \n",
        "    prioritized_fields=PrioritizedFields(  \n",
        "        prioritized_content_fields=[SemanticField(field_name=\"chunk\")]  \n",
        "    ),  \n",
        ")  \n",
        "  \n",
        "# Create the semantic settings with the configuration  \n",
        "semantic_settings = SemanticSettings(configurations=[semantic_config])  \n",
        "  \n",
        "# Create the search index with the semantic settings  \n",
        "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_settings=semantic_settings)  \n",
        "result = index_client.create_or_update_index(index)  \n",
        "print(f\"{result.name} created\")  \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1698513508683
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a skillset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a skillset  \n",
        "skillset_name = f\"{index_name}-skillset\"  \n",
        "  \n",
        "split_skill = SplitSkill(  \n",
        "    description=\"Split skill to chunk documents\",  \n",
        "    text_split_mode=\"pages\",  \n",
        "    context=\"/document\",\n",
        "    default_language_code=\"ja\",  #ページ分割するときに日本語指定しておくと一応考慮される様子\n",
        "    maximum_page_length=1024, # 要検証（英語の元版は2048） \n",
        "    page_overlap_length=20,  \n",
        "    inputs=[  \n",
        "        InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),  \n",
        "    ],  \n",
        "    outputs=[  \n",
        "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
        "    ],  \n",
        ")  \n",
        "  \n",
        "embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
        "    description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
        "    context=\"/document/pages/*\",  \n",
        "    resource_uri=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),  \n",
        "    deployment_id=model,  \n",
        "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
        "    inputs=[  \n",
        "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
        "    ],  \n",
        "    outputs=[  \n",
        "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")  \n",
        "    ],  \n",
        ")  \n",
        "  \n",
        "index_projections = SearchIndexerIndexProjections(  \n",
        "    selectors=[  \n",
        "        SearchIndexerIndexProjectionSelector(  \n",
        "            target_index_name=index_name,  \n",
        "            parent_key_field_name=\"parent_id\",  \n",
        "            source_context=\"/document/pages/*\",  \n",
        "            mappings=[  \n",
        "                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),  \n",
        "                InputFieldMappingEntry(name=\"vector\", source=\"/document/pages/*/vector\"),  \n",
        "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),  \n",
        "                InputFieldMappingEntry(name=\"blob\", source=\"/document/metadata_storage_path\"),   #blobのURLも追加\n",
        "            ],  \n",
        "        ),  \n",
        "    ],  \n",
        "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
        "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
        "    ),  \n",
        ")  \n",
        "  \n",
        "skillset = SearchIndexerSkillset(  \n",
        "    name=skillset_name,  \n",
        "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
        "    skills=[split_skill, embedding_skill],  \n",
        "    index_projections=index_projections,  \n",
        ")  \n",
        "  \n",
        "client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))  \n",
        "client.create_or_update_skillset(skillset)  \n",
        "print(f\"{skillset.name} created\")  \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1698514139334
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an indexer"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an indexer  \n",
        "indexer_name = f\"{index_name}-indexer\"  \n",
        "  \n",
        "indexer = SearchIndexer(  \n",
        "    name=indexer_name,  \n",
        "    description=\"Indexer to index documents and generate embeddings\",  \n",
        "    skillset_name=skillset_name,  \n",
        "    target_index_name=index_name,  \n",
        "    data_source_name=data_source.name,  \n",
        "    # Map the metadata_storage_name field to the title field in the index to display the PDF title in the search results  \n",
        "    field_mappings=[FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"title\")]  \n",
        ")  \n",
        "  \n",
        "indexer_client = SearchIndexerClient(service_endpoint, AzureKeyCredential(key))  \n",
        "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
        "  \n",
        "# Run the indexer  \n",
        "indexer_client.run_indexer(indexer_name)  \n",
        "print(f' {indexer_name} created')  \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1698514307630
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Perform a vector similarity search"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example shows a pure vector search using the vectorizable text query, all you need to do is pass in text and your vectorizer will handle the query vectorization."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Pure Vector Search\n",
        "query = \"重力場を構成する要素は?\"  \n",
        "  \n",
        "search_client = SearchClient(service_endpoint, index_name, credential=credential)\n",
        "vector_query = VectorizableTextQuery(text=query, k=1, fields=\"vector\", exhaustive=True)\n",
        "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
        "# vector_query = RawVectorQuery(vector=generate_embeddings(query), k=3, fields=\"vector\")\n",
        "  \n",
        "results = search_client.search(  \n",
        "    search_text=None,  \n",
        "    vector_queries= [vector_query],\n",
        "    select=[\"parent_id\", \"chunk_id\", \"chunk\", \"blob\"],\n",
        "    top=1\n",
        ")  \n",
        "  \n",
        "for result in results:  \n",
        "    print(f\"parent_id: {result['parent_id']}\")  \n",
        "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
        "    print(f\"Score: {result['@search.score']}\")  \n",
        "    print(f\"Content: {result['chunk']}\")   \n",
        "    print(f\"Source: {result['blob']}\")   \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1698514624886
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform a hybrid search"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Hybrid Search\n",
        "query = \"重力場を構成する要素は?\"  \n",
        "  \n",
        "search_client = SearchClient(service_endpoint, index_name, credential=credential)\n",
        "vector_query = VectorizableTextQuery(text=query, k=1, fields=\"vector\", exhaustive=True)\n",
        "  \n",
        "results = search_client.search(  \n",
        "    search_text=query,  \n",
        "    vector_queries= [vector_query],\n",
        "    select=[\"parent_id\", \"chunk_id\", \"chunk\", \"blob\"],\n",
        "    top=1\n",
        ")  \n",
        "  \n",
        "for result in results:  \n",
        "    print(f\"parent_id: {result['parent_id']}\")  \n",
        "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
        "    print(f\"Score: {result['@search.score']}\")  \n",
        "    print(f\"Content: {result['chunk']}\")  \n",
        "    print(f\"Source: {result['blob']}\")   \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1698514681910
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform a hybrid search + semantic reranking"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Semantic Hybrid Search\n",
        "query = \"重力場を構成する要素は？\"\n",
        "\n",
        "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n",
        "vector_query = VectorizableTextQuery(text=query, k=2, fields=\"vector\", exhaustive=True)\n",
        "\n",
        "results = search_client.search(  \n",
        "    search_text=query,\n",
        "    vector_queries=[vector_query],\n",
        "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
        "    query_type=QueryType.SEMANTIC, query_language=QueryLanguage.JA_JP, semantic_configuration_name='my-semantic-config', query_caption=QueryCaptionType.EXTRACTIVE, query_answer=QueryAnswerType.EXTRACTIVE,\n",
        "    top=2\n",
        ")\n",
        "\n",
        "semantic_answers = results.get_answers()\n",
        "for answer in semantic_answers:\n",
        "    if answer.highlights:\n",
        "        print(f\"Semantic Answer: {answer.highlights}\")\n",
        "    else:\n",
        "        print(f\"Semantic Answer: {answer.text}\")\n",
        "    print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
        "\n",
        "for result in results:\n",
        "    print(f\"parent_id: {result['parent_id']}\")  \n",
        "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
        "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
        "    print(f\"Content: {result['chunk']}\")  \n",
        "\n",
        "    captions = result[\"@search.captions\"]\n",
        "    if captions:\n",
        "        caption = captions[0]\n",
        "        if caption.highlights:\n",
        "            print(f\"Caption: {caption.highlights}\\n\")\n",
        "        else:\n",
        "            print(f\"Caption: {caption.text}\\n\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1698514737525
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}